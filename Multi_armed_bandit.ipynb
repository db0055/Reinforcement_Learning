{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9rNEviFwsxxnklDox0idG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/db0055/Reinforcement_Learning/blob/main/Multi_armed_bandit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVjgrcDoYqdb",
        "outputId": "bc23aa2a-9105-47e6-c775-943b55df2115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6944.547253627731\n",
            "Machine a - True Mean: 4, Estimated Mean: 3.24, Average Reward: 6.94\n",
            "Machine b - True Mean: 3, Estimated Mean: 1.86, Average Reward: 6.94\n",
            "Machine c - True Mean: 5, Estimated Mean: 3.32, Average Reward: 6.94\n",
            "Machine d - True Mean: 7, Estimated Mean: 6.96, Average Reward: 6.94\n",
            "Machine e - True Mean: 2, Estimated Mean: 2.04, Average Reward: 6.94\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_arms = 5\n",
        "num_trials = 1000\n",
        "true_means = [4, 3, 5, 7, 2]\n",
        "estimates = np.ones(num_arms) * 10\n",
        "counts = np.zeros(num_arms)\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "\n",
        "for t in range(1, num_trials + 1):\n",
        "    if t <= num_arms:\n",
        "        action = t - 1\n",
        "    else:\n",
        "        action = np.argmax(estimates)\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\"Average Reward: {average_rewards[i]:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_arms = 5\n",
        "num_trials = 1000\n",
        "true_means = [4, 3, 5, 7, 2]\n",
        "estimates = np.ones(num_arms) * 10\n",
        "counts = np.zeros(num_arms)\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "machine_executions = np.zeros(num_arms)\n",
        "\n",
        "for t in range(1, num_trials + 1):\n",
        "    if t <= num_arms:\n",
        "        action = t - 1\n",
        "    else:\n",
        "        action = np.argmax(estimates)\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "    machine_executions[action] += 1\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\"Average Reward: {average_rewards[i]:.2f}, Executions: {machine_executions[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkmLsY5da4XA",
        "outputId": "50e1b233-cc8e-4fa5-95c3-4f32c4cfdb39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6958.79744010356\n",
            "Machine a - True Mean: 4, Estimated Mean: 4.03, Average Reward: 6.96, Executions: 1.0\n",
            "Machine b - True Mean: 3, Estimated Mean: 4.00, Average Reward: 6.96, Executions: 1.0\n",
            "Machine c - True Mean: 5, Estimated Mean: 4.74, Average Reward: 6.96, Executions: 1.0\n",
            "Machine d - True Mean: 7, Estimated Mean: 6.97, Average Reward: 6.96, Executions: 996.0\n",
            "Machine e - True Mean: 2, Estimated Mean: 2.34, Average Reward: 6.96, Executions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_arms = 5\n",
        "num_trials = 1000\n",
        "true_means = [4, 3, 5, 7, 2]\n",
        "estimates = np.ones(num_arms) * 10\n",
        "counts = np.zeros(num_arms)\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "machine_executions = np.zeros(num_arms)\n",
        "\n",
        "for t in range(1, num_trials + 1):\n",
        "    action = np.argmax(estimates)  # Choose the action with the highest estimated mean\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "    machine_executions[action] += 1\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\"Average Reward: {average_rewards[i]:.2f}, Executions: {machine_executions[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e0Dn6kCbY4H",
        "outputId": "6ad99a0a-ad09-43e2-a9f7-1148cd7825bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6958.262740710286\n",
            "Machine a - True Mean: 4, Estimated Mean: 4.29, Average Reward: 6.96, Executions: 1.0\n",
            "Machine b - True Mean: 3, Estimated Mean: 3.07, Average Reward: 6.96, Executions: 1.0\n",
            "Machine c - True Mean: 5, Estimated Mean: 4.56, Average Reward: 6.96, Executions: 1.0\n",
            "Machine d - True Mean: 7, Estimated Mean: 6.97, Average Reward: 6.96, Executions: 996.0\n",
            "Machine e - True Mean: 2, Estimated Mean: 0.75, Average Reward: 6.96, Executions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_arms = 5\n",
        "num_trials = 1000\n",
        "true_means = [4, 3, 5, 7, 2]\n",
        "estimates = np.ones(num_arms) * 10\n",
        "counts = np.zeros(num_arms)\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "machine_executions = np.zeros(num_arms)\n",
        "\n",
        "for t in range(1, num_trials + 1):\n",
        "    action = np.argmax(estimates)  # Choose the action with the highest estimated mean (purely greedy)\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "    machine_executions[action] += 1\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "print(f\"Average Reward:  {average_rewards[i]:.2f}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\"Number of Run : {int(counts[i])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFBwstQ8cqCR",
        "outputId": "e827c4ec-cdc8-4f95-afb8-fdc453c0149c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6939.284439560552\n",
            "Average Reward:  6.94\n",
            "Machine a - True Mean: 4, Estimated Mean: 3.92, Number of Run : 1\n",
            "Machine b - True Mean: 3, Estimated Mean: 2.73, Number of Run : 1\n",
            "Machine c - True Mean: 5, Estimated Mean: 4.03, Number of Run : 1\n",
            "Machine d - True Mean: 7, Estimated Mean: 6.96, Number of Run : 996\n",
            "Machine e - True Mean: 2, Estimated Mean: 1.34, Number of Run : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_arms = 5\n",
        "num_trials = 1000\n",
        "true_means = [4, 3, 5, 7, 2]\n",
        "estimates = np.ones(num_arms) * 10\n",
        "counts = np.zeros(num_arms)\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "machine_executions = np.zeros(num_arms)\n",
        "epsilon = 0.1\n",
        "\n",
        "for t in range(1, num_trials + 1):\n",
        "    if np.random.rand() < epsilon:\n",
        "\n",
        "        action = np.random.randint(num_arms)\n",
        "    else:\n",
        "\n",
        "        action = np.argmax(estimates)\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "    machine_executions[action] += 1\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\"Number of Runs: {int(counts[i])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbaTNkK0e49_",
        "outputId": "d5bbf156-42b8-4e49-abc3-6645659fc835"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6736.2772693675315\n",
            "Machine a - True Mean: 4, Estimated Mean: 4.30, Number of Runs: 26\n",
            "Machine b - True Mean: 3, Estimated Mean: 3.24, Number of Runs: 18\n",
            "Machine c - True Mean: 5, Estimated Mean: 5.00, Number of Runs: 20\n",
            "Machine d - True Mean: 7, Estimated Mean: 7.02, Number of Runs: 916\n",
            "Machine e - True Mean: 2, Estimated Mean: 1.58, Number of Runs: 20\n"
          ]
        }
      ]
    }
  ]
}